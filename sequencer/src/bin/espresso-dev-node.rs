use std::{collections::BTreeMap, io, iter::once, sync::Arc, time::Duration};

use async_std::task::spawn;
use async_trait::async_trait;
use clap::Parser;
use contract_bindings::light_client_mock::LightClientMock;
use espresso_types::SeqTypes;
use ethers::{
    middleware::{MiddlewareBuilder, SignerMiddleware},
    providers::{Http, Middleware, Provider},
    signers::{coins_bip39::English, MnemonicBuilder, Signer},
    types::{Address, U256},
};
use futures::{future::BoxFuture, FutureExt};
use hotshot_state_prover::service::{
    one_honest_threshold, run_prover_service_with_stake_table, AltChainConfig, AltChainInfo,
    StateProverConfig,
};
use hotshot_types::traits::{
    node_implementation::NodeType,
    stake_table::{SnapshotVersion, StakeTableScheme},
};
use portpicker::pick_unused_port;
use sequencer::{
    api::{
        options,
        test_helpers::{TestNetwork, TestNetworkConfigBuilder, STAKE_TABLE_CAPACITY_FOR_TEST},
    },
    persistence,
    state_signature::relay_server::run_relay_server,
    testing::TestConfigBuilder,
};
use sequencer_utils::{
    deployer::{deploy, Contract, Contracts},
    logging, AnvilOptions,
};
use serde::{Deserialize, Serialize};
use tide_disco::{error::ServerError, method::ReadState, Api, Error as _, StatusCode};
use url::Url;
use vbs::version::StaticVersionType;

#[derive(Clone, Debug, Parser)]
struct Args {
    /// A JSON-RPC endpoint for the L1 to deploy to. If this is not provided, an Avil node will be
    /// launched automatically.
    #[clap(short, long, env = "ESPRESSO_SEQUENCER_L1_PROVIDER")]
    rpc_url: Option<Url>,
    /// Mnemonic for an L1 wallet.
    ///
    /// This wallet is used to deploy the contracts, so the account indicated by ACCOUNT_INDEX must
    /// be funded with with ETH.
    #[clap(
        long,
        name = "MNEMONIC",
        env = "ESPRESSO_SEQUENCER_ETH_MNEMONIC",
        default_value = "test test test test test test test test test test test junk"
    )]
    mnemonic: String,
    /// Account index in the L1 wallet generated by MNEMONIC to use when deploying the contracts.
    #[clap(
        long,
        name = "ACCOUNT_INDEX",
        env = "ESPRESSO_DEPLOYER_ACCOUNT_INDEX",
        default_value = "0"
    )]
    account_index: u32,

    /// Optional list of URLs representing alternate chains where the dev node will deploy LC contracts
    /// and submit LC state updates.
    ///
    /// Useful for test environments involving L3s.
    #[arg(long, env = "ESPRESSO_DEPLOYER_ALT_CHAIN_PROVIDERS", num_args = 1.., value_delimiter = ',')]
    alt_chain_providers: Vec<Url>,

    /// Optional list of mnemonics for the alternate chains. If there are fewer mnemonics provided than chains, the base MNEMONIC will be used.
    #[arg(long, env = "ESPRESSO_DEPLOYER_ALT_MNEMONICS", num_args = 1.., value_delimiter = ',')]
    alt_mnemonics: Vec<String>,

    /// Alternate account indices generated by the mnemonics to use when deploying the contracts. If there are fewer indices provided than chains, the base ACCOUNT_INDEX will be used.
    #[clap(
        long,
        env = "ESPRESSO_SEQUENCER_DEPLOYER_ALT_INDICES",
        default_value = "0"
    )]
    alt_account_indices: Vec<u32>,

    /// Port that the HTTP API will use.
    #[clap(long, env = "ESPRESSO_SEQUENCER_API_PORT")]
    sequencer_api_port: u16,

    /// Maximum concurrent connections allowed by the HTTP API server.
    #[clap(long, env = "ESPRESSO_SEQUENCER_MAX_CONNECTIONS")]
    sequencer_api_max_connections: Option<usize>,

    /// Port for connecting to the builder.
    #[clap(short, long, env = "ESPRESSO_BUILDER_PORT")]
    builder_port: Option<u16>,

    /// Port for connecting to the prover.
    #[clap(short, long, env = "ESPRESSO_PROVER_PORT")]
    prover_port: Option<u16>,

    /// Port for the dev node.
    ///
    /// This is used to provide tools and information to facilitate developers debugging.
    #[clap(short, long, env = "ESPRESSO_DEV_NODE_PORT", default_value = "20000")]
    dev_node_port: u16,

    #[clap(flatten)]
    sql: persistence::sql::Options,

    #[clap(flatten)]
    logging: logging::Config,
}

#[async_std::main]
async fn main() -> anyhow::Result<()> {
    let cli_params = Args::parse();

    let Args {
        rpc_url,
        mnemonic,
        account_index,
        alt_chain_providers,
        alt_mnemonics,
        alt_account_indices,
        sequencer_api_port,
        sequencer_api_max_connections,
        builder_port,
        prover_port,
        dev_node_port,
        sql,
        logging,
    } = cli_params;

    logging.init();

    let api_options = options::Options::from(options::Http {
        port: sequencer_api_port,
        max_connections: sequencer_api_max_connections,
    })
    .status(Default::default())
    .state(Default::default())
    .submit(Default::default())
    .query_sql(Default::default(), sql);

    let (l1_url, _anvil) = if let Some(url) = rpc_url {
        (url, None)
    } else {
        tracing::warn!("L1 url is not provided. running an anvil node");
        let instance = AnvilOptions::default().spawn().await;
        let url = instance.url();
        tracing::info!("l1 url: {}", url);
        (url, Some(instance))
    };

    let relay_server_port = pick_unused_port().unwrap();
    let relay_server_url: Url = format!("http://localhost:{}", relay_server_port)
        .parse()
        .unwrap();

    let network_config = TestConfigBuilder::default()
        .builder_port(builder_port)
        .state_relay_url(relay_server_url.clone())
        .l1_url(l1_url.clone())
        .build();

    const NUM_NODES: usize = 2;
    let config = TestNetworkConfigBuilder::<NUM_NODES, _, _>::with_num_nodes()
        .api_config(api_options)
        .network_config(network_config)
        .build();

    let network = TestNetwork::new(config, <SeqTypes as NodeType>::Base::instance()).await;

    let config = network.cfg.hotshot_config();
    tracing::info!("Hotshot config {config:?}");

    let contracts = Contracts::new();
    let light_client_genesis = network.light_client_genesis();

    let mut wallets = vec![];
    let mut light_client_addresses = vec![];
    let mut mock_contracts = BTreeMap::new();

    // deploy contract for L1 and each alt chain
    for (url, mnemonic, account_index) in once((l1_url.clone(), mnemonic.clone(), account_index))
        .chain(
            alt_chain_providers
                .iter()
                .zip(alt_mnemonics.into_iter().chain(std::iter::repeat(mnemonic)))
                .zip(
                    alt_account_indices
                        .into_iter()
                        .chain(std::iter::repeat(account_index)),
                )
                .map(|((u, m), i)| (u.clone(), m, i)),
        )
    {
        tracing::info!("deploying the contract for provider: {url:?}");

        let contracts = deploy(
            url.clone(),
            mnemonic.clone(),
            account_index,
            true,
            None,
            async { Ok(light_client_genesis.clone()) }.boxed(),
            contracts.clone(),
        )
        .await?;

        let provider = Provider::<Http>::try_from(url.as_str()).unwrap();
        let chain_id = provider.get_chainid().await.unwrap().as_u64();

        let wallet = MnemonicBuilder::<English>::default()
            .phrase(mnemonic.as_str())
            .index(account_index)
            .expect("error building wallet")
            .build()
            .expect("error opening wallet")
            .with_chain_id(chain_id);

        let light_client_address = contracts
            .get_contract_address(Contract::LightClientProxy)
            .unwrap();

        mock_contracts.insert(
            chain_id,
            LightClientMock::new(
                light_client_address,
                Arc::new(provider.with_signer(wallet.clone())),
            ),
        );
        light_client_addresses.push((chain_id, light_client_address));
        wallets.push(wallet.clone());
    }

    let st = network.cfg.stake_table();
    let total_stake = st.total_stake(SnapshotVersion::LastEpochStart).unwrap();
    spawn(run_relay_server(
        None,
        one_honest_threshold(total_stake),
        format!("http://0.0.0.0:{relay_server_port}")
            .parse()
            .unwrap(),
        <SeqTypes as NodeType>::Base::instance(),
    ));

    let update_interval = Duration::from_secs(20);
    let retry_interval = Duration::from_secs(2);
    let prover_port = prover_port.unwrap_or_else(|| pick_unused_port().unwrap());

    let mut signing_keys = wallets
        .iter()
        .map(|wallet| wallet.signer().clone())
        .collect::<Vec<_>>();

    // we remove the first entry which is for L1 light client contract
    // so only alt chain light client addresses are left
    let (_, l1_lc) = light_client_addresses.remove(0);

    // we remove the first entry which is for primary L1 chain signing key
    // so only alt signing keys are left
    let l1_signing_key = signing_keys.remove(0);

    let alt_chains = alt_chain_providers
        .iter()
        .zip(light_client_addresses.clone())
        .zip(signing_keys)
        .map(
            |((provider, (chain_id, light_client_address)), signing_key)| AltChainConfig {
                provider: provider.clone(),
                chain_id,
                light_client_address,
                signing_key,
            },
        )
        .collect();

    let prover_config = StateProverConfig {
        relay_server: relay_server_url.clone(),
        update_interval,
        retry_interval,
        sequencer_url: "http://localhost".parse().unwrap(),
        port: Some(prover_port),
        stake_table_capacity: STAKE_TABLE_CAPACITY_FOR_TEST as usize,
        l1_provider: l1_url.clone(),
        light_client_address: l1_lc,
        eth_signing_key: l1_signing_key,
        alt_chains,
    };

    spawn(run_prover_service_with_stake_table(
        prover_config,
        <SeqTypes as NodeType>::Base::instance(),
        Arc::new(st),
    ));

    let dev_info = DevInfo {
        builder_url: network.cfg.hotshot_config().builder_urls[0].clone(),
        prover_port,
        l1_url,
        l1_light_client_address: l1_lc,
        alt_chains: alt_chain_providers
            .into_iter()
            .zip(light_client_addresses)
            .map(|(prov, (id, addr))| AltChainInfo::new(prov, id, addr))
            .collect(),
    };

    run_dev_node_server(
        dev_node_port,
        mock_contracts,
        dev_info,
        <SeqTypes as NodeType>::Base::instance(),
    )
    .await?;

    Ok(())
}

// ApiState is passed to the tide disco app so avoid cloning the contracts for each endpoint
pub struct ApiState<S: Signer + Clone + 'static>(
    BTreeMap<u64, LightClientMock<SignerMiddleware<Provider<Http>, S>>>,
);

#[async_trait]
impl<S: Signer + Clone + 'static> ReadState for ApiState<S> {
    type State = ApiState<S>;
    async fn read<T>(
        &self,
        op: impl Send + for<'a> FnOnce(&'a Self::State) -> BoxFuture<'a, T> + 'async_trait,
    ) -> T {
        op(self).await
    }
}

async fn run_dev_node_server<Ver: StaticVersionType + 'static, S: Signer + Clone + 'static>(
    port: u16,
    contracts: BTreeMap<u64, LightClientMock<SignerMiddleware<Provider<Http>, S>>>,
    dev_info: DevInfo,
    bind_version: Ver,
) -> anyhow::Result<()> {
    let mut app = tide_disco::App::<_, ServerError>::with_state(ApiState(contracts));
    let toml =
        toml::from_str::<toml::value::Value>(include_str!("../../api/espresso_dev_node.toml"))
            .map_err(|err| io::Error::new(io::ErrorKind::Other, err))?;

    let mut api = Api::<_, ServerError, Ver>::new(toml)
        .map_err(|err| io::Error::new(io::ErrorKind::Other, err))?;
    api.get("devinfo", move |_, _| {
        let info = dev_info.clone();
        async move { Ok(info.clone()) }.boxed()
    })
    .map_err(|err| io::Error::new(io::ErrorKind::Other, err))?
    .at("sethotshotdown", move |req, state: &ApiState<S>| {
        async move {
            let body = req
                .body_auto::<SetHotshotDownReqBody, Ver>(Ver::instance())
                .map_err(ServerError::from_request_error)?;

            // if chain id is not provided, primary L1 light client is used
            let contract = if let Some(chain_id) = body.chain_id {
                state.0.get(&chain_id).ok_or_else(|| {
                    ServerError::catch_all(
                        StatusCode::INTERNAL_SERVER_ERROR,
                        "light client contract not found for chain id {chain_id}".to_string(),
                    )
                })?
            } else {
                let (_, contract) = state.0.first_key_value().ok_or_else(|| {
                    ServerError::catch_all(
                        StatusCode::INTERNAL_SERVER_ERROR,
                        "L1 light client contract not found ".to_string(),
                    )
                })?;

                contract
            };

            let contract_call = contract.set_hot_shot_down_since(U256::from(body.height));

            contract_call.send().await.map_err(|err| {
                ServerError::catch_all(StatusCode::INTERNAL_SERVER_ERROR, err.to_string())
            })?;
            Ok(())
        }
        .boxed()
    })
    .map_err(|err| io::Error::new(io::ErrorKind::Other, err))?
    .at("sethotshotup", move |req, state| {
        async move {
            let chain_id = req
                .body_auto::<Option<SetHotshotUpReqBody>, Ver>(Ver::instance())
                .map_err(ServerError::from_request_error)?
                .map(|b| b.chain_id);

            // if chain id is not provided, we use the base L1 light client contract
            let contract = if let Some(chain_id) = chain_id {
                state.0.get(&chain_id).ok_or_else(|| {
                    ServerError::catch_all(
                        StatusCode::INTERNAL_SERVER_ERROR,
                        "light client ontract not found".to_string(),
                    )
                })?
            } else {
                let (_, light_client_address) = state.0.first_key_value().ok_or_else(|| {
                    ServerError::catch_all(
                        StatusCode::INTERNAL_SERVER_ERROR,
                        "l1 light client ontract not found".to_string(),
                    )
                })?;

                light_client_address
            };

            contract.set_hot_shot_up().send().await.map_err(|err| {
                ServerError::catch_all(StatusCode::INTERNAL_SERVER_ERROR, err.to_string())
            })?;
            Ok(())
        }
        .boxed()
    })
    .map_err(|err| io::Error::new(io::ErrorKind::Other, err))?;

    app.register_module("api", api)
        .map_err(|err| io::Error::new(io::ErrorKind::Other, err))?;

    app.serve(format!("0.0.0.0:{port}"), bind_version).await?;

    Ok(())
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct DevInfo {
    pub builder_url: Url,
    pub prover_port: u16,
    pub l1_url: Url,
    pub l1_light_client_address: Address,
    pub alt_chains: Vec<AltChainInfo>,
}

#[derive(Debug, Serialize, Deserialize)]
struct SetHotshotDownReqBody {
    // return l1 light client if not provided
    pub chain_id: Option<u64>,
    pub height: u64,
}

#[derive(Debug, Serialize, Deserialize)]
struct SetHotshotUpReqBody {
    pub chain_id: u64,
}

#[cfg(test)]
mod tests {
    use std::{process::Child, sync::Arc, time::Duration};

    use async_std::{stream::StreamExt, task::sleep};
    use committable::{Commitment, Committable};
    use contract_bindings::light_client::LightClient;
    use escargot::CargoBuild;
    use espresso_types::{BlockMerkleTree, Header, SeqTypes, Transaction};
    use ethers::{providers::Middleware, types::U256};
    use futures::TryStreamExt;
    use hotshot_query_service::{
        availability::{BlockQueryData, TransactionQueryData, VidCommonQueryData},
        data_source::sql::testing::TmpDb,
    };
    use hotshot_types::traits::node_implementation::NodeType;
    use jf_merkle_tree::MerkleTreeScheme;
    use portpicker::pick_unused_port;
    use sequencer::api::endpoints::NamespaceProofQueryData;
    use sequencer_utils::{init_signer, test_utils::setup_test, AnvilOptions};
    use surf_disco::Client;
    use tide_disco::error::ServerError;
    use vbs::version::StaticVersion;

    use crate::{DevInfo, SetHotshotDownReqBody};

    const TEST_MNEMONIC: &str = "test test test test test test test test test test test junk";

    pub struct BackgroundProcess(Child);

    impl Drop for BackgroundProcess {
        fn drop(&mut self) {
            self.0.kill().unwrap();
        }
    }

    // If this test failed and you are doing changes on the following stuff, please
    // sync your changes to [`espresso-sequencer-go`](https://github.com/EspressoSystems/espresso-sequencer-go)
    // and open a PR.
    // - APIs update
    // - Types (like `Header`) update
    #[async_std::test]
    async fn dev_node_test() {
        setup_test();

        let builder_port = pick_unused_port().unwrap();

        let api_port = pick_unused_port().unwrap();

        let dev_node_port = pick_unused_port().unwrap();

        let instance = AnvilOptions::default().spawn().await;
        let l1_url = instance.url();

        let db = TmpDb::init().await;
        let postgres_port = db.port();

        let process = CargoBuild::new()
            .bin("espresso-dev-node")
            .features("testing")
            .current_target()
            .run()
            .unwrap()
            .command()
            .env("ESPRESSO_SEQUENCER_L1_PROVIDER", l1_url.to_string())
            .env("ESPRESSO_BUILDER_PORT", builder_port.to_string())
            .env("ESPRESSO_SEQUENCER_API_PORT", api_port.to_string())
            .env("ESPRESSO_SEQUENCER_POSTGRES_HOST", "localhost")
            .env("ESPRESSO_SEQUENCER_ETH_MNEMONIC", TEST_MNEMONIC)
            .env("ESPRESSO_DEPLOYER_ACCOUNT_INDEX", "0")
            .env("ESPRESSO_DEV_NODE_PORT", dev_node_port.to_string())
            .env(
                "ESPRESSO_SEQUENCER_POSTGRES_PORT",
                postgres_port.to_string(),
            )
            .env("ESPRESSO_SEQUENCER_POSTGRES_USER", "postgres")
            .env("ESPRESSO_SEQUENCER_POSTGRES_PASSWORD", "password")
            .spawn()
            .unwrap();

        let _process = BackgroundProcess(process);

        let api_client: Client<ServerError, <SeqTypes as NodeType>::Base> =
            Client::new(format!("http://localhost:{api_port}").parse().unwrap());
        api_client.connect(None).await;

        tracing::info!("waiting for blocks");
        let _ = api_client
            .socket("availability/stream/blocks/0")
            .subscribe::<BlockQueryData<SeqTypes>>()
            .await
            .unwrap()
            .take(5)
            .try_collect::<Vec<_>>()
            .await
            .unwrap();

        let builder_api_client: Client<ServerError, StaticVersion<0, 1>> =
            Client::new(format!("http://localhost:{builder_port}").parse().unwrap());
        builder_api_client.connect(None).await;

        let builder_address = builder_api_client
            .get::<String>("block_info/builderaddress")
            .send()
            .await
            .unwrap();

        assert!(!builder_address.is_empty());

        let tx = Transaction::new(100_u32.into(), vec![1, 2, 3]);

        let hash: Commitment<Transaction> = api_client
            .post("submit/submit")
            .body_json(&tx)
            .unwrap()
            .send()
            .await
            .unwrap();

        let tx_hash = tx.commit();
        assert_eq!(hash, tx_hash);

        let mut tx_result = api_client
            .get::<TransactionQueryData<SeqTypes>>(&format!(
                "availability/transaction/hash/{tx_hash}",
            ))
            .send()
            .await;
        while tx_result.is_err() {
            sleep(Duration::from_secs(3)).await;

            tx_result = api_client
                .get::<TransactionQueryData<SeqTypes>>(&format!(
                    "availability/transaction/hash/{}",
                    tx_hash
                ))
                .send()
                .await;
        }

        let large_tx = Transaction::new(100_u32.into(), vec![0; 20000]);
        let large_hash: Commitment<Transaction> = api_client
            .post("submit/submit")
            .body_json(&large_tx)
            .unwrap()
            .send()
            .await
            .unwrap();

        let tx_hash = large_tx.commit();
        assert_eq!(large_hash, tx_hash);

        let mut tx_result = api_client
            .get::<TransactionQueryData<SeqTypes>>(&format!(
                "availability/transaction/hash/{tx_hash}",
            ))
            .send()
            .await;
        while tx_result.is_err() {
            tracing::info!("waiting for large tx");
            sleep(Duration::from_secs(3)).await;

            tx_result = api_client
                .get::<TransactionQueryData<SeqTypes>>(&format!(
                    "availability/transaction/hash/{}",
                    tx_hash
                ))
                .send()
                .await;
        }

        // Now the `submit/submit` endpoint allows the extremely large transactions to be in the mempool.
        // And we need to check whether this extremely large transaction blocks the building process.
        // Currently the default value of `max_block_size` is 30720, and this transaction exceeds the limit.
        // TODO: https://github.com/EspressoSystems/espresso-sequencer/issues/1777
        {
            let extremely_large_tx = Transaction::new(100_u32.into(), vec![0; 50120]);
            let extremely_large_hash: Commitment<Transaction> = api_client
                .post("submit/submit")
                .body_json(&extremely_large_tx)
                .unwrap()
                .send()
                .await
                .unwrap();
            assert_eq!(extremely_large_tx.commit(), extremely_large_hash);

            // Now we send a small transaction to make sure this transaction can be included in a hotshot block.
            let tx = Transaction::new(100_u32.into(), vec![0; 3]);
            let tx_hash: Commitment<Transaction> = api_client
                .post("submit/submit")
                .body_json(&tx)
                .unwrap()
                .send()
                .await
                .unwrap();

            let mut result = api_client
                .get::<TransactionQueryData<SeqTypes>>(&format!(
                    "availability/transaction/hash/{tx_hash}",
                ))
                .send()
                .await;
            while result.is_err() {
                sleep(Duration::from_secs(3)).await;

                result = api_client
                    .get::<TransactionQueryData<SeqTypes>>(&format!(
                        "availability/transaction/hash/{}",
                        tx_hash
                    ))
                    .send()
                    .await;
            }
        }

        let tx_block_height = tx_result.unwrap().block_height();

        // Check the namespace proof
        let proof = api_client
            .get::<NamespaceProofQueryData>(&format!(
                "availability/block/{tx_block_height}/namespace/100"
            ))
            .send()
            .await
            .unwrap();
        assert!(proof.proof.is_some());

        // These endpoints are currently used in `espresso-sequencer-go`. These checks
        // serve as reminders of syncing the API updates to go client repo when they change.
        {
            api_client
                .get::<u64>("status/block-height")
                .send()
                .await
                .unwrap();

            api_client
                .get::<Header>("availability/header/3")
                .send()
                .await
                .unwrap();

            api_client
                .get::<VidCommonQueryData<SeqTypes>>(&format!(
                    "availability/vid/common/{tx_block_height}"
                ))
                .send()
                .await
                .unwrap();

            while api_client
                .get::<<BlockMerkleTree as MerkleTreeScheme>::MembershipProof>("block-state/3/2")
                .send()
                .await
                .is_err()
            {
                sleep(Duration::from_secs(3)).await;
            }
        }

        let dev_node_client: Client<ServerError, <SeqTypes as NodeType>::Base> =
            Client::new(format!("http://localhost:{dev_node_port}").parse().unwrap());
        dev_node_client.connect(None).await;

        // Check the dev node api
        {
            tracing::info!("checking the dev node api");
            let dev_info = dev_node_client
                .get::<DevInfo>("api/dev-info")
                .send()
                .await
                .unwrap();

            let light_client_address = dev_info.l1_light_client_address;

            let signer = init_signer(&l1_url, TEST_MNEMONIC, 0).await.unwrap();
            let light_client = LightClient::new(light_client_address, Arc::new(signer.clone()));

            while light_client
                .get_hot_shot_commitment(U256::from(1))
                .call()
                .await
                .is_err()
            {
                tracing::info!("waiting for commitment");
                sleep(Duration::from_secs(3)).await;
            }

            let height = signer.get_block_number().await.unwrap().as_u64();
            dev_node_client
                .post::<()>("api/set-hotshot-down")
                .body_json(&SetHotshotDownReqBody {
                    chain_id: None,
                    height: height - 1,
                })
                .unwrap()
                .send()
                .await
                .unwrap();

            while !light_client
                .lag_over_escape_hatch_threshold(U256::from(height), U256::from(0))
                .call()
                .await
                .unwrap_or(false)
            {
                tracing::info!("waiting for setting hotshot down");
                sleep(Duration::from_secs(3)).await;
            }

            dev_node_client
                .post::<()>("api/set-hotshot-up")
                .body_json(&())
                .unwrap()
                .send()
                .await
                .unwrap();

            while light_client
                .lag_over_escape_hatch_threshold(U256::from(height), U256::from(0))
                .call()
                .await
                .unwrap_or(true)
            {
                tracing::info!("waiting for setting hotshot up");
                sleep(Duration::from_secs(3)).await;
            }
        }

        drop(db);
    }
}
