use std::{io, sync::Arc, time::Duration};

use async_std::task::spawn;
use clap::Parser;
use contract_bindings::light_client_mock::LightClientMock;
use espresso_types::SeqTypes;
use ethers::{
    middleware::{MiddlewareBuilder, SignerMiddleware},
    providers::{Http, Middleware, Provider},
    signers::{coins_bip39::English, MnemonicBuilder, Signer},
    types::{Address, U256},
};
use futures::FutureExt;
use hotshot_state_prover::service::{
    one_honest_threshold, run_prover_service_with_stake_table, StateProverConfig,
};
use hotshot_types::traits::{
    node_implementation::NodeType,
    stake_table::{SnapshotVersion, StakeTableScheme},
};
use portpicker::pick_unused_port;
use sequencer::{
    api::{
        options,
        test_helpers::{TestNetwork, TestNetworkConfigBuilder, STAKE_TABLE_CAPACITY_FOR_TEST},
    },
    persistence,
    state_signature::relay_server::run_relay_server,
    testing::TestConfigBuilder,
};
use sequencer_utils::{
    deployer::{deploy, Contract, Contracts},
    logging, AnvilOptions,
};
use serde::{Deserialize, Serialize};
use tide_disco::{error::ServerError, Api, Error as _, StatusCode};
use url::Url;
use vbs::version::StaticVersionType;

#[derive(Clone, Debug, Parser)]
struct Args {
    /// A JSON-RPC endpoint for the L1 to deploy to. If this is not provided, an Avil node will be
    /// launched automatically.
    #[clap(short, long, env = "ESPRESSO_SEQUENCER_L1_PROVIDER")]
    rpc_url: Option<Url>,
    /// Mnemonic for an L1 wallet.
    ///
    /// This wallet is used to deploy the contracts, so the account indicated by ACCOUNT_INDEX must
    /// be funded with with ETH.
    #[clap(
        long,
        name = "MNEMONIC",
        env = "ESPRESSO_SEQUENCER_ETH_MNEMONIC",
        default_value = "test test test test test test test test test test test junk"
    )]
    mnemonic: String,
    /// Account index in the L1 wallet generated by MNEMONIC to use when deploying the contracts.
    #[clap(
        long,
        name = "ACCOUNT_INDEX",
        env = "ESPRESSO_DEPLOYER_ACCOUNT_INDEX",
        default_value = "0"
    )]
    account_index: u32,

    /// Optional list of URLs representing alternate chains where the dev node will deploy LC contracts
    /// and submit LC state updates.
    ///
    /// Useful for test environments involving L3s.
    #[arg(long, env = "ESPRESSO_DEPLOYER_ALT_CHAIN_PROVIDERS", num_args = 1.., value_delimiter = ',')]
    alt_chain_providers: Vec<Url>,

    /// Optional list of mnemonics for the alternate chains. If there are fewer mnemonics provided than chains, the base MNEMONIC will be used.
    #[arg(long, env = "ESPRESSO_DEPLOYER_ALT_MNEMONICS", num_args = 1.., value_delimiter = ',')]
    alt_mnemonics: Vec<String>,

    /// Alternate account indices generated by the mnemonics to use when deploying the contracts. If there are fewer indices provided than chains, the base ACCOUNT_INDEX will be used.
    #[clap(
        long,
        env = "ESPRESSO_SEQUENCER_DEPLOYER_ALT_INDICES",
        default_value = "0"
    )]
    alt_account_indices: Vec<u32>,

    /// Port that the HTTP API will use.
    #[clap(long, env = "ESPRESSO_SEQUENCER_API_PORT")]
    sequencer_api_port: u16,

    /// Maximum concurrent connections allowed by the HTTP API server.
    #[clap(long, env = "ESPRESSO_SEQUENCER_MAX_CONNECTIONS")]
    sequencer_api_max_connections: Option<usize>,

    /// Port for connecting to the builder.
    #[clap(short, long, env = "ESPRESSO_BUILDER_PORT")]
    builder_port: Option<u16>,

    /// Port for connecting to the prover.
    #[clap(short, long, env = "ESPRESSO_PROVER_PORT")]
    prover_port: Option<u16>,

    /// Port for the dev node.
    ///
    /// This is used to provide tools and information to facilitate developers debugging.
    #[clap(short, long, env = "ESPRESSO_DEV_NODE_PORT", default_value = "20000")]
    dev_node_port: u16,

    #[clap(flatten)]
    sql: persistence::sql::Options,

    #[clap(flatten)]
    logging: logging::Config,
}

#[async_std::main]
async fn main() -> anyhow::Result<()> {
    let mut cli_params = Args::parse();
    cli_params.logging.init();

    let api_options = options::Options::from(options::Http {
        port: cli_params.sequencer_api_port,
        max_connections: cli_params.sequencer_api_max_connections,
    })
    .status(Default::default())
    .state(Default::default())
    .submit(Default::default())
    .query_sql(Default::default(), cli_params.sql);

    let (url, _anvil) = if let Some(url) = cli_params.rpc_url {
        (url, None)
    } else {
        tracing::warn!("L1 url is not provided. running an anvil node");
        let instance = AnvilOptions::default().spawn().await;
        let url = instance.url();
        tracing::info!("l1 url: {}", url);
        (url, Some(instance))
    };

    let relay_server_port = pick_unused_port().unwrap();
    let relay_server_url: Url = format!("http://localhost:{}", relay_server_port)
        .parse()
        .unwrap();

    let network_config = TestConfigBuilder::default()
        .builder_port(cli_params.builder_port)
        .state_relay_url(relay_server_url.clone())
        .l1_url(url.clone())
        .build();

    const NUM_NODES: usize = 2;
    let config = TestNetworkConfigBuilder::<NUM_NODES, _, _>::with_num_nodes()
        .api_config(api_options)
        .network_config(network_config)
        .build();

    let network = TestNetwork::new(config, <SeqTypes as NodeType>::Base::instance()).await;

    let config = network.cfg.hotshot_config();
    tracing::info!("Hotshot config {config:?}");

    let contracts = Contracts::new();

    tracing::info!("deploying the contracts");

    let light_client_genesis = network.light_client_genesis();

    let chain_providers = {
        let mut urls = vec![url.clone()];
        urls.append(&mut cli_params.alt_chain_providers);
        urls
    };

    let num_providers = chain_providers.len();

    let mnemonics = {
        let mut mnem = vec![cli_params.mnemonic.clone()];
        mnem.append(&mut cli_params.alt_mnemonics);
        mnem.resize(num_providers, cli_params.mnemonic.clone());
        mnem
    };

    let account_indices = {
        let mut indices = vec![cli_params.account_index];
        indices.append(&mut cli_params.alt_account_indices);
        indices.resize(num_providers, cli_params.account_index);
        indices
    };

    let mut wallets = vec![];
    let mut light_client_addresses = vec![];

    for (i, provider_url) in chain_providers.clone().into_iter().enumerate() {
        let contracts = deploy(
            provider_url,
            mnemonics[i].clone(),
            account_indices[i],
            true,
            None,
            async { Ok(light_client_genesis.clone()) }.boxed(),
            contracts.clone(),
        )
        .await?;

        // Run the relay server
        let provider = Provider::<Http>::try_from(url.as_str()).unwrap();
        let chain_id = provider.get_chainid().await.unwrap().as_u64();

        let wallet = MnemonicBuilder::<English>::default()
            .phrase(cli_params.mnemonic.as_str())
            .index(cli_params.account_index)
            .expect("error building wallet")
            .build()
            .expect("error opening wallet")
            .with_chain_id(chain_id);

        let light_client_address = contracts
            .get_contract_address(Contract::LightClientProxy)
            .unwrap();
        light_client_addresses.push(light_client_address);
        wallets.push(wallet);
    }

    let st = network.cfg.stake_table();
    let total_stake = st.total_stake(SnapshotVersion::LastEpochStart).unwrap();
    spawn(run_relay_server(
        None,
        one_honest_threshold(total_stake),
        format!("http://0.0.0.0:{relay_server_port}")
            .parse()
            .unwrap(),
        <SeqTypes as NodeType>::Base::instance(),
    ));

    let update_interval = Duration::from_secs(20);
    let retry_interval = Duration::from_secs(2);
    let prover_port = cli_params
        .prover_port
        .unwrap_or_else(|| pick_unused_port().unwrap());

    let config = StateProverConfig {
        relay_server: relay_server_url.clone(),
        update_interval,
        retry_interval,
        chain_providers: chain_providers.clone(),
        light_client_addresses: light_client_addresses.clone(),
        eth_signing_keys: wallets
            .clone()
            .into_iter()
            .map(|wallet| wallet.signer().clone())
            .collect(),
        sequencer_url: "http://localhost".parse().unwrap(), // This should not be used in dev-node
        port: Some(prover_port),
        stake_table_capacity: STAKE_TABLE_CAPACITY_FOR_TEST as usize,
    };

    spawn(run_prover_service_with_stake_table(
        config,
        <SeqTypes as NodeType>::Base::instance(),
        Arc::new(st),
    ));

    let dev_info = DevInfo {
        builder_url: network.cfg.hotshot_config().builder_urls[0].clone(),
        prover_port,
        l1_url: chain_providers[0].clone(),
        light_client_address: light_client_addresses[0],
    };

    let base_provider = Provider::<Http>::try_from(chain_providers[0].as_str()).unwrap();
    let mock_contract = LightClientMock::new(
        light_client_addresses[0],
        Arc::new(base_provider.with_signer(wallets[0].clone())),
    );

    run_dev_node_server(
        cli_params.dev_node_port,
        mock_contract,
        dev_info,
        <SeqTypes as NodeType>::Base::instance(),
    )
    .await?;

    Ok(())
}

async fn run_dev_node_server<Ver: StaticVersionType + 'static, S: Signer + Clone + 'static>(
    port: u16,
    mock_contract: LightClientMock<SignerMiddleware<Provider<Http>, S>>,
    dev_info: DevInfo,
    bind_version: Ver,
) -> anyhow::Result<()> {
    let mut app = tide_disco::App::<(), ServerError>::with_state(());
    let toml =
        toml::from_str::<toml::value::Value>(include_str!("../../api/espresso_dev_node.toml"))
            .map_err(|err| io::Error::new(io::ErrorKind::Other, err))?;

    let mut api = Api::<(), ServerError, Ver>::new(toml)
        .map_err(|err| io::Error::new(io::ErrorKind::Other, err))?;

    api.get("devinfo", move |_, _| {
        let info = dev_info.clone();
        async move { Ok(info.clone()) }.boxed()
    })
    .map_err(|err| io::Error::new(io::ErrorKind::Other, err))?;

    let contract = mock_contract.clone();
    api.post("sethotshotdown", move |req, _| {
        let contract = contract.clone();
        async move {
            let height = req
                .body_auto::<SetHotshotUpBody, Ver>(Ver::instance())
                .map_err(ServerError::from_request_error)?
                .height;
            contract
                .set_hot_shot_down_since(U256::from(height))
                .send()
                .await
                .map_err(|err| {
                    ServerError::catch_all(StatusCode::INTERNAL_SERVER_ERROR, err.to_string())
                })?;
            Ok(())
        }
        .boxed()
    })
    .map_err(|err| io::Error::new(io::ErrorKind::Other, err))?;

    api.post("sethotshotup", move |_, _| {
        let contract = mock_contract.clone();
        async move {
            contract.set_hot_shot_up().send().await.map_err(|err| {
                ServerError::catch_all(StatusCode::INTERNAL_SERVER_ERROR, err.to_string())
            })?;
            Ok(())
        }
        .boxed()
    })
    .map_err(|err| io::Error::new(io::ErrorKind::Other, err))?;

    app.register_module("api", api)
        .map_err(|err| io::Error::new(io::ErrorKind::Other, err))?;

    app.serve(format!("0.0.0.0:{port}"), bind_version).await?;

    Ok(())
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct DevInfo {
    pub builder_url: Url,
    pub prover_port: u16,
    pub l1_url: Url,
    pub light_client_address: Address,
}

#[derive(Debug, Serialize, Deserialize)]
struct SetHotshotUpBody {
    pub height: u64,
}

#[cfg(test)]
mod tests {
    use std::{process::Child, sync::Arc, time::Duration};

    use async_std::{stream::StreamExt, task::sleep};
    use committable::{Commitment, Committable};
    use contract_bindings::light_client::LightClient;
    use escargot::CargoBuild;
    use espresso_types::{BlockMerkleTree, Header, SeqTypes, Transaction};
    use ethers::{
        providers::Middleware,
        types::{Address, U256},
    };
    use futures::TryStreamExt;
    use hotshot_query_service::{
        availability::{BlockQueryData, TransactionQueryData, VidCommonQueryData},
        data_source::sql::testing::TmpDb,
    };
    use hotshot_types::traits::node_implementation::NodeType;
    use jf_merkle_tree::MerkleTreeScheme;
    use portpicker::pick_unused_port;
    use sequencer::api::endpoints::NamespaceProofQueryData;
    use sequencer_utils::{init_signer, test_utils::setup_test, AnvilOptions};
    use surf_disco::Client;
    use tide_disco::error::ServerError;
    use vbs::version::StaticVersion;

    use crate::{DevInfo, SetHotshotUpBody};

    const TEST_MNEMONIC: &str = "test test test test test test test test test test test junk";

    pub struct BackgroundProcess(Child);

    impl Drop for BackgroundProcess {
        fn drop(&mut self) {
            self.0.kill().unwrap();
        }
    }

    // If this test failed and you are doing changes on the following stuff, please
    // sync your changes to [`espresso-sequencer-go`](https://github.com/EspressoSystems/espresso-sequencer-go)
    // and open a PR.
    // - APIs update
    // - Types (like `Header`) update
    #[async_std::test]
    async fn dev_node_test() {
        setup_test();

        let builder_port = pick_unused_port().unwrap();

        let api_port = pick_unused_port().unwrap();

        let dev_node_port = pick_unused_port().unwrap();

        let instance = AnvilOptions::default().spawn().await;
        let l1_url = instance.url();

        let db = TmpDb::init().await;
        let postgres_port = db.port();

        let process = CargoBuild::new()
            .bin("espresso-dev-node")
            .features("testing")
            .current_target()
            .run()
            .unwrap()
            .command()
            .env("ESPRESSO_SEQUENCER_L1_PROVIDER", l1_url.to_string())
            .env("ESPRESSO_BUILDER_PORT", builder_port.to_string())
            .env("ESPRESSO_SEQUENCER_API_PORT", api_port.to_string())
            .env("ESPRESSO_SEQUENCER_POSTGRES_HOST", "localhost")
            .env("ESPRESSO_SEQUENCER_ETH_MNEMONIC", TEST_MNEMONIC)
            .env("ESPRESSO_DEPLOYER_ACCOUNT_INDEX", "0")
            .env("ESPRESSO_DEV_NODE_PORT", dev_node_port.to_string())
            .env(
                "ESPRESSO_SEQUENCER_POSTGRES_PORT",
                postgres_port.to_string(),
            )
            .env("ESPRESSO_SEQUENCER_POSTGRES_USER", "postgres")
            .env("ESPRESSO_SEQUENCER_POSTGRES_PASSWORD", "password")
            .spawn()
            .unwrap();

        let _process = BackgroundProcess(process);

        let api_client: Client<ServerError, <SeqTypes as NodeType>::Base> =
            Client::new(format!("http://localhost:{api_port}").parse().unwrap());
        api_client.connect(None).await;

        tracing::info!("waiting for blocks");
        let _ = api_client
            .socket("availability/stream/blocks/0")
            .subscribe::<BlockQueryData<SeqTypes>>()
            .await
            .unwrap()
            .take(5)
            .try_collect::<Vec<_>>()
            .await
            .unwrap();

        let builder_api_client: Client<ServerError, StaticVersion<0, 1>> =
            Client::new(format!("http://localhost:{builder_port}").parse().unwrap());
        builder_api_client.connect(None).await;

        let builder_address = builder_api_client
            .get::<String>("block_info/builderaddress")
            .send()
            .await
            .unwrap();

        assert!(!builder_address.is_empty());

        let tx = Transaction::new(100_u32.into(), vec![1, 2, 3]);

        let hash: Commitment<Transaction> = api_client
            .post("submit/submit")
            .body_json(&tx)
            .unwrap()
            .send()
            .await
            .unwrap();

        let tx_hash = tx.commit();
        assert_eq!(hash, tx_hash);

        let mut tx_result = api_client
            .get::<TransactionQueryData<SeqTypes>>(&format!(
                "availability/transaction/hash/{tx_hash}",
            ))
            .send()
            .await;
        while tx_result.is_err() {
            sleep(Duration::from_secs(3)).await;

            tx_result = api_client
                .get::<TransactionQueryData<SeqTypes>>(&format!(
                    "availability/transaction/hash/{}",
                    tx_hash
                ))
                .send()
                .await;
        }

        let large_tx = Transaction::new(100_u32.into(), vec![0; 20000]);
        let large_hash: Commitment<Transaction> = api_client
            .post("submit/submit")
            .body_json(&large_tx)
            .unwrap()
            .send()
            .await
            .unwrap();

        let tx_hash = large_tx.commit();
        assert_eq!(large_hash, tx_hash);

        let mut tx_result = api_client
            .get::<TransactionQueryData<SeqTypes>>(&format!(
                "availability/transaction/hash/{tx_hash}",
            ))
            .send()
            .await;
        while tx_result.is_err() {
            tracing::info!("waiting for large tx");
            sleep(Duration::from_secs(3)).await;

            tx_result = api_client
                .get::<TransactionQueryData<SeqTypes>>(&format!(
                    "availability/transaction/hash/{}",
                    tx_hash
                ))
                .send()
                .await;
        }

        // Now the `submit/submit` endpoint allows the extremely large transactions to be in the mempool.
        // And we need to check whether this extremely large transaction blocks the building process.
        // Currently the default value of `max_block_size` is 30720, and this transaction exceeds the limit.
        // TODO: https://github.com/EspressoSystems/espresso-sequencer/issues/1777
        {
            let extremely_large_tx = Transaction::new(100_u32.into(), vec![0; 50120]);
            let extremely_large_hash: Commitment<Transaction> = api_client
                .post("submit/submit")
                .body_json(&extremely_large_tx)
                .unwrap()
                .send()
                .await
                .unwrap();
            assert_eq!(extremely_large_tx.commit(), extremely_large_hash);

            // Now we send a small transaction to make sure this transaction can be included in a hotshot block.
            let tx = Transaction::new(100_u32.into(), vec![0; 3]);
            let tx_hash: Commitment<Transaction> = api_client
                .post("submit/submit")
                .body_json(&tx)
                .unwrap()
                .send()
                .await
                .unwrap();

            let mut result = api_client
                .get::<TransactionQueryData<SeqTypes>>(&format!(
                    "availability/transaction/hash/{tx_hash}",
                ))
                .send()
                .await;
            while result.is_err() {
                sleep(Duration::from_secs(3)).await;

                result = api_client
                    .get::<TransactionQueryData<SeqTypes>>(&format!(
                        "availability/transaction/hash/{}",
                        tx_hash
                    ))
                    .send()
                    .await;
            }
        }

        let tx_block_height = tx_result.unwrap().block_height();

        let light_client_address = "0xdc64a140aa3e981100a9beca4e685f962f0cf6c9";

        let signer = init_signer(&l1_url, TEST_MNEMONIC, 0).await.unwrap();
        let light_client = LightClient::new(
            light_client_address.parse::<Address>().unwrap(),
            Arc::new(signer.clone()),
        );

        while light_client
            .get_hot_shot_commitment(U256::from(1))
            .call()
            .await
            .is_err()
        {
            tracing::info!("waiting for commitment");
            sleep(Duration::from_secs(3)).await;
        }

        // Check the namespace proof
        let proof = api_client
            .get::<NamespaceProofQueryData>(&format!(
                "availability/block/{tx_block_height}/namespace/100"
            ))
            .send()
            .await
            .unwrap();
        assert!(proof.proof.is_some());

        // These endpoints are currently used in `espresso-sequencer-go`. These checks
        // serve as reminders of syncing the API updates to go client repo when they change.
        {
            api_client
                .get::<u64>("status/block-height")
                .send()
                .await
                .unwrap();

            api_client
                .get::<Header>("availability/header/3")
                .send()
                .await
                .unwrap();

            api_client
                .get::<VidCommonQueryData<SeqTypes>>(&format!(
                    "availability/vid/common/{tx_block_height}"
                ))
                .send()
                .await
                .unwrap();

            while api_client
                .get::<<BlockMerkleTree as MerkleTreeScheme>::MembershipProof>("block-state/3/2")
                .send()
                .await
                .is_err()
            {
                sleep(Duration::from_secs(3)).await;
            }
        }

        let dev_node_client: Client<ServerError, <SeqTypes as NodeType>::Base> =
            Client::new(format!("http://localhost:{dev_node_port}").parse().unwrap());
        dev_node_client.connect(None).await;

        // Check the dev node api
        {
            tracing::info!("checking the dev node api");
            dev_node_client
                .get::<DevInfo>("api/dev-info")
                .send()
                .await
                .unwrap();

            let height = signer.get_block_number().await.unwrap().as_u64();
            dev_node_client
                .post::<()>("api/set-hotshot-down")
                .body_json(&SetHotshotUpBody { height: height - 1 })
                .unwrap()
                .send()
                .await
                .unwrap();

            while !light_client
                .lag_over_escape_hatch_threshold(U256::from(height), U256::from(0))
                .call()
                .await
                .unwrap_or(false)
            {
                tracing::info!("waiting for setting hotshot down");
                sleep(Duration::from_secs(3)).await;
            }

            dev_node_client
                .post::<()>("api/set-hotshot-up")
                .send()
                .await
                .unwrap();

            while light_client
                .lag_over_escape_hatch_threshold(U256::from(height), U256::from(0))
                .call()
                .await
                .unwrap_or(true)
            {
                tracing::info!("waiting for setting hotshot up");
                sleep(Duration::from_secs(3)).await;
            }
        }

        drop(db);
    }
}
